<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="./">
    <title>Chapter 17: MLLM 新内容：RAG 热词识别、上下文增强与说话人知识注入</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="stylesheet" href="assets/highlight.css">
    <script src="assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>目录</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <div class="sidebar-search">
                <input type="text" id="sidebar-search-input" placeholder="搜索..." autocomplete="off">
            </div>
            <div id="tree-container">
                <nav class="tree-nav" role="tree">
                    <div class="tree-item " >
                        <a href="index.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">ASR 与 Speaker Diarization 训练中文教程（多语种：中英及主要语种｜RNN → Conv+LSTM → MLLM）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter1.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 1: 任务全景：ASR 与 Diarization 的训练对象、边界与通用流水线</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter2.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 2: 工程与实验基线：环境、框架、分布式与可复现</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter3.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 3: 数据与标注：采集、清洗、切分、对齐与许可</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter4.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 4: 文本规范化全家桶：TN / ITN / OpenCC / 混语与混脚本</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter5.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 5: 音频预处理与切分：VAD、重叠、对齐与波形级增广</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter6.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 6: 特征与前端：从 MFCC 到可学习前端，再到 SSL 表征</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter7.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 7: RNN 时代 ASR：从 LSTM/GRU 到 CTC/Attention（并讨论对 MLLM 的启示）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter8.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 8：Conv + LSTM 时代：CLDNN/CRDNN/TDNN-LSTM 与流式工程</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter9.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 9: Transformer 自监督过渡：Conformer、Transducer 与 SSL 微调</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter10.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 10: Speaker Diarization 经典流水线：SAD + Embedding + Clustering + Resegmentation</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter11.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 11: 神经 Diarization 与端到端联合：EEND、TS-VAD、SA-ASR</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter12.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 12: 多语种与混语训练 (Multilingual & Code-Switching)</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter13.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 13: 评测与误差分析——ASR (WER/CER/MER) 与 Diarization (DER/JER) 的细节陷阱</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter14.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 14: 开源工具链与训练配方：Kaldi / ESPnet / NeMo / WeNet / FunASR / Pyannote</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter15.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 15: 开源数据集大全：ASR / 多语种 / 会议 / 噪声 / Diarization</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter16.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 16: MLLM 时代：从 Speech Foundation Model 到“可对话的语音智能体”</span>
                        </a>
                    </div>
                
                    <div class="tree-item active" >
                        <a href="chapter17.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 17: MLLM 新内容：RAG 热词识别、上下文增强与说话人知识注入</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter18.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 18: 生产化落地：流式、延迟、部署、监控、隐私与安全</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter19.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 19: 附录 A：TN / ITN 速查与工程实战手册</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter20.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 20: 附录 B：OpenCC、脚本映射与正则工具箱（深度实战版）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter21.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 21: 附录 C - 术语表、常见问答 (FAQ) 与进阶阅读</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="CLAUDE.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Untitled</span>
                        </a>
                    </div>
                </nav>
            </div>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="chapter-17-mllm-rag">Chapter 17: MLLM 新内容：RAG 热词识别、上下文增强与说话人知识注入</h1>
<h2 id="171">17.1 开篇与学习目标</h2>
<p>在 ASR 发展的历史长河中（如 Chapter 7-9 所述），"Contextual Biasing"（上下文偏置）一直是一个核心难题。在 WFST 时代，我们通过修改解码图（H-Level 或 G-Level）来硬性插入热词；在端到端（E2E）时代，我们使用 Shallow Fusion 或 Neural Contextual Biasing 模块。</p>
<p>到了 MLLM（Multimodal Large Language Model）时代，游戏规则变了。模型不再仅仅是一个声学概率计算器，而是一个具备推理能力的智能体。ASR 任务逐渐演变成了<strong>“基于音频证据的指令遵循任务”</strong>。我们不再需要费力地修改底层解码图，而通过 <strong>RAG（Retrieval-Augmented Generation）</strong> 将外部知识动态注入到 Prompt 中。</p>
<p>然而，MLLM 也带来了新的风险：它可能因为“过度聪明”而根据上下文编造音频中未出现的内容（幻觉）。本章将深入探讨如何驾驭这股力量，构建既精准又可控的下一代 ASR 系统。</p>
<p><strong>本章学习目标</strong>：</p>
<ol>
<li><strong>深入理解 ASR-RAG 的特殊性</strong>：为什么文本 RAG 的“语义检索”在语音热词任务中往往失效？如何构建“声学检索器”？</li>
<li><strong>掌握热词注入的三种范式</strong>：从单纯的 Prompting 到 Logit Bias，再到两阶段（2-pass）修正。</li>
<li><strong>学会利用 Diarization 进行个性化识别</strong>：如何将 Speaker Embedding 转化为 RAG 的检索键。</li>
<li><strong>构建防御性解码策略</strong>：如何通过置信度校验和局部重写（Partial Rewriting）抑制幻觉。</li>
<li><strong>建立新的评测指标</strong>：学习 Bias-WER (B-WER) 和 Unbiased-WER (U-WER) 以量化 RAG 的收益与代价。</li>
</ol>
<hr />
<h2 id="172-asr-rag">17.2 核心机制：ASR 专用的 RAG 流水线</h2>
<p>与传统的文本问答 RAG 不同，ASR 的输入是<strong>模糊的声学信号</strong>或<strong>包含错误的初步转写</strong>。因此，直接使用 BERT/Embedding 进行语义检索通常效果不佳（例如：用户说了“买<strong>也是</strong>”，ASR 识别为“买<strong>椰氏</strong>”，语义向量天差地别）。</p>
<p>我们需要构建一个 <strong>ASR 专用的 RAG 流水线</strong>：</p>
<h3 id="1721">17.2.1 检索策略：声学相似度 &gt; 语义相似度</h3>
<p>在 ASR 场景下，<strong>“听起来像”</strong>比“意思相近”更重要。</p>
<ol>
<li>
<p><strong>索引构建 (Indexing)</strong>：
* <strong>Key</strong>: 热词本身（如 "DeepSeek"）。
* <strong>Phonetic Key</strong>: 热词的音素序列（如 <code>/d i p s i k/</code>）或拼音（<code>di pu xi ke</code>）。
* <strong>Fuzzy Key</strong>: 使用 Metaphone, Soundex 或简单的字符 N-gram 生成模糊键。</p>
</li>
<li>
<p><strong>查询生成 (Query Generation)</strong>：
* <strong>源</strong>: ASR 的初步解码结果（1-best 或 N-best hypothesis）。
* <strong>变换</strong>: 将初步结果转换为音素/拼音序列。</p>
</li>
<li>
<p><strong>检索匹配 (Retrieval)</strong>：
* 使 <strong>加权编辑距离 (Weighted Edit Distance)</strong> 计算 Query 音素序列与知识库 Key 音素序列的相似度。
* <strong>Rule of Thumb</strong>: 对于缩写词（如 "AI", "App"），字符级匹配权重更高；对于长实体（如 "阿达木单抗"），音素级匹配权重更高。</p>
</li>
</ol>
<h3 id="1722">17.2.2 流程架构图</h3>
<div class="codehilite"><pre><span></span><code><span class="k">[知识库 Preparation]</span>
<span class="na">实体</span><span class="o">:</span><span class="w"> </span><span class="s">&quot;Zweihander&quot; -&gt; G2P -&gt; /z w aɪ h æ n d ər/ -&gt; 存入向量库/倒排索引</span>

<span class="k">[Runtime Process]</span>

<span class="na">1. Audio Input  ----(Speech Encoder)----&gt; Acoustic Embeddings</span>
<span class="w">                                              </span><span class="na">|</span>

<span class="na">2. First Pass   ----(Fast Decoder)------&gt; &quot;Please call two hander team&quot; (ASR Error)</span>
<span class="w">                                              </span><span class="na">|</span>

<span class="na">3. Phonetic Search (关键步骤)</span>
<span class="w">   </span><span class="na">Query</span><span class="o">:</span><span class="w"> </span><span class="s">&quot;two hander&quot; -&gt; /t u h æ n d ər/</span>
<span class="w">   </span><span class="na">Match</span><span class="o">:</span><span class="w"> </span><span class="s">/t u h æ n d ər/ vs /z w aɪ h æ n d ər/ (Distance &lt; Threshold)</span>
<span class="w">   </span><span class="na">Retrieve</span><span class="o">:</span><span class="w"> </span><span class="s">&quot;Zweihander&quot;</span>
<span class="w">                                              </span><span class="na">|</span>

<span class="na">4. Context Construction</span>
<span class="w">   </span><span class="na">Prompt</span><span class="o">:</span><span class="w"> </span><span class="s">&quot;The user might be mentioning: [&#39;Zweihander&#39;].</span>
<span class="w">            </span><span class="na">Audio evidence suggests specific terms. </span>
<span class="w">            </span><span class="na">Transcribe faithfully.&quot;</span>
<span class="w">                                              </span><span class="na">|</span>

<span class="na">5. Second Pass (MLLM)</span>
<span class="w">   </span><span class="na">Input</span><span class="o">:</span><span class="w"> </span><span class="s">Acoustic Embeddings + Prompt</span>
<span class="w">   </span><span class="na">Output</span><span class="o">:</span><span class="w"> </span><span class="s">&quot;Please call Zweihander team&quot;</span>
</code></pre></div>

<hr />
<h2 id="173">17.3 热词注入与偏置方法演进</h2>
<p>在 MLLM 框架下，我们有多种手段让模型“注意到”这些检索回来的热词。</p>
<h3 id="1731-prompting">17.3.1 Prompting (指令引导)</h3>
<p>这是最直接的方法，利用 LLM 的 In-context Learning 能力。</p>
<ul>
<li><strong>Naive Prompt</strong>: "Possible hotwords: [A, B, C]. Transcribe the audio."</li>
<li><strong>Structure-Aware Prompt</strong> (推荐):</li>
</ul>
<div class="codehilite"><pre><span></span><code><span class="gh"># Instruction</span>
You are an expert ASR system. Below is a list of specialized vocabulary that MAY appear in the audio.

<span class="gh"># Vocabulary</span>

<span class="k">-</span><span class="w"> </span>&quot;Retin-A&quot; (Medical drug)
<span class="k">-</span><span class="w"> </span>&quot;Tretinoin&quot; (Generic name)

<span class="gh"># Constraints</span>

<span class="k">-</span><span class="w"> </span>Only use the vocabulary if the audio strictly matches the pronunciation.
<span class="k">-</span><span class="w"> </span>Do NOT hallucinate words just because they are in the list.

<span class="gh"># Audio Context</span>
[Audio Embeddings inserted here]
</code></pre></div>

<h3 id="1732-biased-decoding-logit">17.3.2 Biased Decoding (Logit 偏置)</h3>
<p>如果 Prompting 效果不稳定（模型视而不见），可以在解码层面施加硬约束。这类似于 Shallow Fusion 的 MLLM 版本。</p>
<ul>
<li><strong>原理</strong>: 在 LLM 生成每一个 Token 时，检查该 Token 是否属于检索到的热词的前缀。如果是，人为增加该 Token 的 Logit 值。</li>
<li><strong>挑战</strong>: MLLM 的 Tokenizer（如 Tiktoken, SentencePiece）可能将一个热词切碎（如 <code>TensorFlow</code> -&gt; <code>Ten</code>, <code>sor</code>, <code>Flow</code>）。必须构建 <strong>Trie (前缀树)</strong> 来通过 Token 边界进行匹配。</li>
</ul>
<h3 id="1733-tool-use-agentic-asr">17.3.3 Tool-Use / Agentic ASR (工具调用模式)</h3>
<p>这是 MLLM 的高级用法。将“查词典”作为一个 Tool。</p>
<ul>
<li>
<p><strong>流程</strong>:
1. MLLM 遇到不确定的发音，输出特殊 Token <code>&lt;lookup&gt; sound_like_xxx &lt;/lookup&gt;</code>。
2. 外部程序捕获该 Token，执行模糊检索。
3. 将检索结果填回 Prompt，MLLM 继续生成。</p>
</li>
<li>
<p><strong>优点</strong>: 极大地减少了 Prompt 长度，只在需要时检索。</p>
</li>
</ul>
<hr />
<h2 id="174-speaker-aware-rag">17.4 说话人知识注入 (Speaker-aware RAG)</h2>
<p>利用 <strong>Chapter 10/11</strong> 的 Diarization 结果，我们可以将“说话人身份”作为最强的上下文线索。</p>
<h3 id="1741-speaker-profile">17.4.1 说话人画像 (Speaker Profile)</h3>
<p>我们可以为每个 Speaker ID 维护一个动态 Profile：</p>
<ul>
<li><strong>静态属性</strong>: 姓名、职位、部门（决定了专用术语表）。</li>
<li><strong>动态历史</strong>: 本次会议中该人已经说过的专有名词（Cache）。</li>
</ul>
<h3 id="1742-role-based-prompting">17.4.2 实现方案：Role-based Prompting</h3>
<p>假设 Diarization 告诉我们：<code>00:00 - 00:15</code> 是 <code>Speaker_A</code> (Doctor)，<code>00:16 - 00:30</code> 是 <code>Speaker_B</code> (Patient)。</p>
<p><strong>Prompt 模板</strong>:</p>
<div class="codehilite"><pre><span></span><code>[Role Definition]
Speaker_A is a Cardiologist. Expect medical terminology (drugs, procedures).
Speaker_B is a Patient. Expect colloquial language, symptom descriptions.

[Transcription Task]
Turn 1 (Speaker_A): &quot;Have you been taking your [MASK]?&quot; -&gt; Bias towards &quot;Warfarin&quot;, &quot;Aspirin&quot;.
Turn 2 (Speaker_B): &quot;Yes, I take the [MASK] one.&quot; -&gt; Bias towards &quot;red&quot;, &quot;small&quot; (common words).
</code></pre></div>

<p>这种方法能极大地解决<strong>同词消歧</strong>问题（例如：医生说的 "MS" 可能是 "Mitral Stenosis" 二尖瓣狭窄，而 IT 人员说的 "MS" 是 "Microsoft"）。</p>
<hr />
<h2 id="175-gotchas-anti-hallucination">17.5 常见陷阱与幻觉控制 (Gotchas &amp; Anti-Hallucination)</h2>
<p>MLLM ASR 最大的噩梦是：知识库里有 "Apple"，用户说了 "Apply"，模型强行转写为 "Apple"。</p>
<h3 id="1751">17.5.1 幻觉成因</h3>
<ol>
<li><strong>Over-trusting context</strong>: 模型在预训练阶段学会了“尽可能利用 Prompt 信息”，导致忽略底层的声学证据。</li>
<li><strong>Tokenization artifact</strong>: 某些罕见热词被切分成极短的 token，导致概率分布极其平坦，容易被 Logit Bias 干扰。</li>
</ol>
<h3 id="1752-defense-engineering">17.5.2 防御工程 (Defense Engineering)</h3>
<ol>
<li>
<p><strong>Confidence-based Selection (置信度门控)</strong>:
* 不要盲目接受 MLLM 的修正。
* 计算 <code>Score(RAG_Result)</code> 和 <code>Score(Original_Result)</code>。只有当 <code>Score(RAG_Result) - Score(Original_Result) &gt; Threshold</code> 时才采纳。</p>
</li>
<li>
<p><strong>Negative Prompting (负向提示)</strong>:
* 明确告诉模型什么<strong>不要做</strong>。
* Prompt: "If the audio sounds like 'Apply' (/ə p l aɪ/), do NOT output 'Apple' (/æ p l/) even if 'Apple' is in the list."</p>
</li>
<li>
<p><strong>Anchor Constraint (锚点约束)</strong>:
* 要求 MLLM 输出时必须携带时间戳。如果热词的时间戳与原音频段严重不符（例如时长差异过大），则丢弃该热词。</p>
</li>
<li>
<p><strong>The "None of the Above" Option</strong>:
* 在热词列表中始终加入一个 <code>&lt;NO_MATCH&gt;</code> 选项，训练模型在声学不匹配时主动选择它。</p>
</li>
</ol>
<hr />
<h2 id="176-wer">17.6 评测体系：不仅仅是 WER</h2>
<p>传统的 WER (Word Error Rate) 无法准确衡量 RAG 的价值。我们需要更细粒度的指标。</p>
<h3 id="1761">17.6.1 专项指标</h3>
<ol>
<li><strong>R-WER (Reference-WER)</strong>: 仅计算热词列表中的词的错误率。</li>
<li><strong>B-WER (Biased-WER)</strong>: 给定热词提示时，热词的召回率（Recall）。目标：越高越好。</li>
<li><strong>U-WER (Unbiased-WER)</strong>: 给定热词提示时，<strong>非热词</strong>部分的错误率。目标：不要升高（即不发生“灾难性遗忘”或“误伤”）。</li>
<li><strong>FPR (False Positive Rate)</strong>: 这是一个关键指标。当 Prompt 中包含热词 X，但音频中<strong>完全没说</strong> X 时，模型幻觉出 X 的概率。</li>
</ol>
<h3 id="1762">17.6.2 对比实验设计</h3>
<p>| 实验组 | Prompt 设置 | 预期结果 | 风险 |</p>
<table>
<thead>
<tr>
<th>实验组</th>
<th>Prompt 设置</th>
<th>预期结果</th>
<th>风险</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Baseline</strong></td>
<td>无热词列表</td>
<td>高 B-WER</td>
<td>漏识别专名</td>
</tr>
<tr>
<td><strong>Oracle</strong></td>
<td>仅包含音频中真实出现的热词</td>
<td>理论上限 (Upper Bound)</td>
<td>无法落地</td>
</tr>
<tr>
<td><strong>RAG-TopK</strong></td>
<td>包含 Top-K 检索结果 (含干扰项)</td>
<td>真实性能</td>
<td>可能触发幻觉</td>
</tr>
<tr>
<td><strong>Distractor</strong></td>
<td>仅包含干扰项 (音频中未出现的词)</td>
<td>评估 FPR</td>
<td>测试抗干扰能力</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="177">17.7 练习题</h2>
<h3 id="_1">基础题</h3>
<details>
<summary><b>1. 为什么直接把几千个员工名字全部塞进 MLLM 的 System Prompt 是不可行的？</b> (点击展开)</summary>
<ul>
<li><strong>提示</strong>：考虑上下文窗口（Context Window）和注意力分散（Attention Dilution）。</li>
<li><strong>答案</strong>：
1. <strong>成本与延迟</strong>：Prompt 越长，首 token 延迟（TTFT）越高，推理成本越贵。
2. <strong>注意稀释</strong>：即 "Lost in the Middle" 现象。当列表过长时，模型往往只能记住开头和结尾的词，中间的词会被忽略。
3. <strong>误报率激增</strong>：候选词越多，撞上“音似词”导致幻觉的概率就越大。</li>
</ul>
</details>
<details>
<summary><b>2. 在构建 ASR 专用的 RAG 检索器时，为什么 "Soundex" 或 "Metaphone" 算法比 "BERT Embedding" 更有效？</b> (点击展开)</summary>
<ul>
<li><strong>提示</strong>：ASR 的错误通常是基于什么的？</li>
<li><strong>答案</strong>：ASR 的初步错误通常是<strong>发音驱动</strong>的（如 "two hander" vs "Zweihander"）。Soundex/Metaphone 是专门将发音编码为代码的算法，能捕捉声学相似性。而 BERT Embedding 基于语义，"two hander" 和 "Zweihander" 在语义空间距离极远，无法被召回。</li>
</ul>
</details>
<h3 id="_2">挑战题</h3>
<details>
<summary><b>3. [系统设计] 设计一个“流式（Streaming）”的 MLLM RAG 方案。由于 MLLM 推理慢，如何避免用户等待太久？</b> (点击展开)</summary>
<ul>
<li><strong>提示</strong>考虑“推测解码”（Speculative Decoding）或“异步修正”架构。</li>
<li><strong>答案</strong>：</li>
<li>
<p><strong>双流架构 (Dual-Stream)</strong>：
1. <strong>Fast Stream</strong>: 使用小模型（如 Conformer-Transducer）实时上屏，延迟低，但可能有错。
2. <strong>Slow Stream (Async)</strong>: 后台异步运行 MLLM + RAG。每隔 5-10 秒（或一个句子结束），对 Fast Stream 的结果进行“回溯修正”。</p>
</li>
<li>
<p><strong>UI 呈现</strong>: 也就是常说的 "Finalization" 机制。用户先看到灰色的初步结果（变动中），几秒后文字变为黑色（MLLM 修正定稿）。</p>
</li>
</ul>
</details>
<details>
<summary><b>4. [Prompt 工程] 编写一个用于“粤语-英语混读”会议记录的 RAG Prompt 模板，要求模型修正专有名词，但保留粤语语气词（如“嘅”、“啫”）。</b> (点击展开)</summary>
<ul>
<li><strong>提示</strong>：利用 Chapter 4 的混语处理知识，强调“Style Preservation”。</li>
<li><strong>答案</strong>：</li>
</ul>
<div class="codehilite"><pre><span></span><code><span class="gh"># Role</span>
You are a Cantonese-English code-switching ASR assistant.

<span class="gh"># Context (Hotwords)</span>

<span class="k">-</span><span class="w"> </span>&quot;Docker&quot;
<span class="k">-</span><span class="w"> </span>&quot;Kubernetes&quot;

<span class="gh"># Rules</span>

<span class="k">1.</span> <span class="gs">**Correction**</span>: If the audio sounds like &quot;Dock 㗎&quot;, and context is technical, correct &quot;Dock&quot; to &quot;Docker&quot;.
<span class="k">2.</span> <span class="gs">**Preservation**</span>: STRICTLY PRESERVE Cantonese sentence-final particles (SFPs) like &quot;嘅&quot;, &quot;啫&quot;, &quot;啦&quot;. Do NOT translate them or remove them.
<span class="k">3.</span> <span class="gs">**Output**</span>: Output the transcribed text directly.

<span class="gh"># Example</span>
Input Audio: &quot;我地用 Kubernete 嘅&quot;
Output: &quot;我地用 Kubernetes 嘅&quot;
</code></pre></div>

</details>
<details>
<summary><b>5. [诊断] 你的 RAG ASR 系统上线后，用户投诉：“我没说这个药名，它自己加上去了”。请列出 3 种排查思路。</b> (点击展开)</summary>
<ul>
<li><strong>提示</strong>：检查检索环节、Prompt 环节和音频质量。</li>
<li><strong>答案</strong>：
1. <strong>检查检索阈值</strong>：是否检索模块的编辑距离阈值设得太宽？导致用户说个普通词（如 "aspirational"）召回了热词（"Aspirin"）。
2. <strong>检查 Prompt 强弱</strong>：是否使用了过于强硬的指令（如 "You MUST use words from the list"）？应改为 "Only use if audio matches"。
3. <strong>检查 Logit Bias</strong>：如果使用了 Logit Bias，是否不仅给热词首 Token 加分了，还给后续 Token 加分过高？导致一旦触发前缀就“刹不住车”。</li>
</ul>
</details>
<hr />
<h2 id="178">17.8 本章小结：迈向可控的智能语音</h2>
<p>Chapter 17 标志着我们从“训练模型”转向“使用模型”。</p>
<ul>
<li><strong>ASR + RAG</strong> 不仅仅是查漏补缺，它是通向<strong>领域自适应（Domain Adaptation）</strong>的捷径，无需重新训练模型即可适配医疗、法律等垂直场景。</li>
<li><strong>Prompt Engineering</strong> 是新的 Feature Engineering。你需要像对待代码一样对待 Prompt，进行版本管理和回归测试。</li>
<li><strong>核心矛盾</strong> 依然是 <strong>召回率 vs. 幻觉</strong>。所有的工程技巧（声学检索、置信度校验、负向提示）都是为了在这个权衡中寻找最优解。</li>
</ul>
            </article>
            
            <nav class="page-nav"><a href="chapter16.html" class="nav-link prev">← Chapter 16: MLLM 时代：从 Speech Foundation Model 到“可对话的语音智能体”</a><a href="chapter18.html" class="nav-link next">Chapter 18: 生产化落地：流式、延迟、部署、监控、隐私与安全 →</a></nav>
        </main>
    </div>
</body>
</html>