# Chapter 19: 附录 A：TN / ITN 速查与工程实战手册

> **本章摘要**：
> 文本规范化（TN）与逆文本规范化（ITN）是 ASR 系统中“最后两公里”的基础设施。本章提供了一份详尽的规则速查表，涵盖中文（普通话/粤语）、英文、混合语境以及特殊符号的处理标准。同时，本章讨论了在工程实现中如何通过正则（Regex）与加权有限状态转换器（WFST）来落地这些规则。

---

## 19.0 核心概念：听觉真值 vs 视觉真值

在开始编写规则之前，必须在团队内部统一以下两个概念，否则标注和训练将陷入混乱：

1. **TN (Text Normalization)  听觉真值 (Auditory Truth)**
* **场景**：ASR 声学模型训练、语言模型（LM）训练。
* **原则**：**所听即所得**。将所有非表音字符（数字、符号、缩写）转换为其发音对应的文字。
* **目标**：消除歧义。模型不应去“猜” `$10` 是读 `ten dollars` 还是 `ten bucks`，TN 必须确定一种读法。


2. **ITN (Inverse Text Normalization)  视觉真值 (Visual Truth)**
* **场景**：ASR 最终结果展示、字幕生成、RAG 检索输入。
* **原则**：**符合书写规范**。将口语化的文字流还原为符合语法、美观、紧凑的书面形式。
* **目标**：可读性与检索性。



| 维度 | 原始文本 (Raw) | TN (训练输入) | ITN (推理输出) | 备注 |
| --- | --- | --- | --- | --- |
| **数字** | `3D打印` | `三 弟 打 印` | `3D打印` | 训练时英文通常大写 |
| **日期** | `2024-01-01` | `二 零 二 四 年 一 月 一 日` | `2024年1月1日` | ITN 需统一格式 |
| **符号** | `50%` | `百 分 之 五 十` | `50%` | 符号读音顺序往往颠倒 |
| **标点** | `Hello!` | `hello` | `Hello!` | 训练通常去标点、转小写 |

---

## 19.1 中文（普通话）深度规范速查

中文处理最大的难点在于**数字的多音字（一/幺，二/两）以及单位与数字的粘连**。

### 19.1.1 数字读法全集 (The "Yi" and "Er" Dilemma)

这是中文 ASR 训练数据的头号杀手。

| 场景 | 数字 | TN (训练读法) | 规则判据 (Rule of Thumb) |
| --- | --- | --- | --- |
| **基数/计数** | `1`, `2` | `一`, `二` | 默认读法。 |
| **数量 (量词前)** | `2个` | `两 个` | 后面紧跟量词（个、只、条、万、亿）。 |
| **位读 (ID/电话)** | `1`, `2` | `幺`, `二` | 电话号码、身份证、房间号。注意：`2` 在号码中通常读 `二`，极少读 `两`。 |
| **年份** | `2011` | `二 零 一 一` | 年份中的 `1` 通常读 `一`，不读 `幺`。 |
| **大数** | `200` | `两 百` / `二 百` | 这是一个**摇摆区**。建议统一规范为 `两百`，或在数据增广时随机替换。 |
| **序数** | `第2` | `第 二` | 前缀为“第”时永远读 `二`。 |
| **小数/分数** | `0.2`, `1/2` | `零 点 二`, `二 分 之 一` | 小数和分母读 `二`。 |

> **工程实现注记**：
> 在编写 TN 脚本时，无法仅靠正则区分 `110` 是“报警电话”（幺幺零）还是“房间号”（一一零）还是“数量”（一百一十）。
> * **策略 A**：使用 NLP Tagger 标注实体类型，再应用规则。
> * **策略 B**：对于模糊情况，保留多种读法生成多条训练数据（Data Augmentation）。
> 
> 

### 19.1.2 日期与时间的正则化

输入格式极度发散，输出（ITN）必须收敛。

| 类型 | 常见输入格式 | TN (Spoken) | ITN 标准化输出 |
| --- | --- | --- | --- |
| **标准日期** | `2023-05-04` | `二零二三年 五月 四日` | `2023年5月4日` |
| **斜杠日期** | `2023/5/4` | `二零二三年 五月 四日` | `2023年5月4日` |
| **点号日期** | `2023.5.4` | `二零二三年 五月 四日` | `2023年5月4日` |
| **口语日期** | `月四号` | `五月 四号` | `5月4日` (将“号”转“日”) |
| **农历** | `腊月二十三` | `腊月 二十三` | `腊月二十三` (通常不转阿拉伯数字) |
| **时间段** | `14:00-15:00` | `十四点 到 十五点` | `14:00-15:00` |

### 19.1.3 货币与计量单位 (Prefix vs Suffix)

中文口语习惯将符号（如 ￥, $）放在数字之后读出单位，书写时却在前面。

| 符号 | 含义 | TN 规则 (Text  Audio) | ITN 规则 (Audio  Text) |
| --- | --- | --- | --- |
| **￥** | RMB | `￥100`  `一百 元` / `一百 块` | `一百元`  `100元` (推荐) 或 `￥100` |
| **$** | Dollar | `$10``十 美元`/`十 刀` | `十美元``$10`或`10美元` |

---

## 19.2 英文（English）深度规范速查

英文 TN 的核心在于**非标准词（NSW）的展开**与**大小写（Truecasing）**。

### 19.2.1 缩写词的分类处理

必须区分 **Acronyms** (连读) 和 **Alphabetisms** (逐字母读)。

| 类型 | 示例 | TN 策略 | 备注 |
| --- | --- | --- | --- |
| **Alphabetisms** | `FBI`, `IBM`, `USA` | `f b i`, `i b m`, `u s a` | 训练时字母间加空格，防止模型学成单词。 |
| **Acronyms** | `NASA`, `JPEG`, `ASAP` | `nasa`, `jay peg`, `a sap` | 需维护读音词典 (Lexicon)。 |
| **混合型** | `JPEG2000` | `jay peg two thousand` | 需切分后分别处理。 |
| **多义缩写** | `Dr.` | `doctor` (Dr. Li) / `drive` (Mulholland Dr.) | 需基于 N-gram 或语法树的上下文判断。 |
| **多义缩写** | `St.` | `saint` (St. Paul) / `street` (Wall St.) | 同上。 |

### 19.2.2 数字的复杂读法

| 类型 | 文本 | TN 变体 (需覆盖多种情况) | ITN 策略 |
| --- | --- | --- | --- |
| **年份** | `1995` | `nineteen ninety five` | `19...` 优先按两位分组识别。 |
| **年份** | `2005` | `two thousand five` (含 `and` 可选) | `2000-2009` 通常读 `thousand`。 |
| **年份** | `2024` | `twenty twenty four` | `2010+` 回归两位分组读法。 |
| **电话** | `0` | `oh` / `zero` | 必须在词表中同时映射 `oh` 和 `zero` 到 `0`。 |
| **货币** | `$2.50` | `two fifty` / `two dollars and fifty cents` | ITN 需支持简读还原。 |
| **罗马数字** | `King Henry VIII` | `king henry the eighth` | 必须展开，否则模型学不到发音。 |

---

## 19.3 多语种混合 (Code-Switching) 实战指南

当一句话中同时出现中文、英文、数字时，**分词符（Tokenization）**的处理决定了系统的上限。

### 19.3.1 核心原则：空格策略 (The Spacing Policy)

> **Golden Rule**: 在训练数据中，**中英文交界处必须插入空格**。

* **错误示例**: `我爱Python编程`
* Token 序列可能变成: `[我, 爱, P, y, t, h, o, n, 编, 程]` (Char-level) 或 `[我, 爱, Py, thon, 编, 程]` (BPE)。
* 后果：BPE 切分不稳定，模型难以学习英文单词边界。


* **正确示例**: `我 爱 Python 编 程`
* 处理流程：
1. 将中文汉字按字切分（加空格）。
2. 检测到连续英文字符串，保持为一个单词（或 BPE token），其前后加格。
3. 检测到数字，根据 TN 规则转为汉字或英文单词。





### 19.3.2 常见混合模式速查

| 原始文本 | TN 处理 (Training Input) | ITN 处理 (User View) | 难点说明 |
| --- | --- | --- | --- |
| `Office 365` | `office three six five` | `Office 365` | 产品名中的数字往往一位位读。 |
| `Windows 10` | `windows ten` | `Windows 10` | 版本号读基数。 |
| `WiFi信号` | `wai fai 信 号` | `Wi-Fi信号` | `WiFi` 常见读音需映射到规范词 `Wi-Fi`。 |
| `App` | `a p p` (逐字) / `app` (单词) | `App` | 两种读法在国内都极常见，需双重支持。 |
| `C#` | `c sharp` | `C#` | 不要写成 `C井`。 |
| `C++` | `c plus plus` | `C++` | 不要写成 `C加加`。 |

---

## 19.4 粤语（Cantonese）特有规范

粤语涉及**三套书写系统**的纠缠：口语字、书面语（标准中文）、拼音（Jyutping）。

| 类别 | 例子 | 处理策略 |
| --- | --- | --- |
| **口语字 (必须保留)** | `嘅` (的), `喺` (在), `咁` (这么) | **TN**: 绝不转为普通话汉字。训练字表必须包含这些字符。<br>

<br>**ITN**: 除非任务是“粤语翻译”，否则保留口语字。 |
| **英粤夹杂** | `我个 file 呢` | **TN**: `我 个 file 呢` (英文保留原词，不转拼音)。<br>

<br>**发音典**: 需为 `file` 标注粤语口音的音素 (如 `f aai1 ou4`) 或直接用英文音素。 |
| **特色词汇** | `士多` (Store), `波士` (Boss) | 作为固定词条处理，不还原为英文。 |
| **正字法 (Gotcha)** | `里度` vs `呢度` (这里) | 粤语正字法不统一。**建议**：训练前选定一套标准（如“粤语审音配词字库”），做**同义词归一化**。 |

---

## 19.5 符号与标点：去留的艺术

### 19.5.1 训练阶段 (TN)

* **标点符号**：通常**全部删除**。对于长停顿，可以插入 `<sil>` 或 `<pause>` 标记。
* **特殊字符**：`+`, `-`, `*`, `/` 必须翻译成文字（加、减、乘、除/斜杠）。
* **Emoji**: 🥲 通常删除，除做情感分析辅助任务。

### 19.5.2 推理阶段 (ITN 后)

* **标点恢复 (Punctuation Restoration)**：这是一个独立的 NLP 模型（通常是 BERT/Transformer-based）。
* **处理顺序**：ASR Output  ITN (转数字/格式)  Punctuation Model (加标点)。
* *理由*：标点模型通常在规范文本上训练，先做 ITN 把 `三点半` 变成 `3:30` 有助于标点模型判断句读。



---

## 19.6 专名与热词的冲突处理 (RAG/Biasing)

当结合 MLLM/RAG 时，TN/ITN 可能会破坏检索键值（Key）。

| 冲突场景 | 问题描述 | 解决方案 |
| --- | --- | --- |
| **检索键不匹配** | 知识库 Key 为 `iPhone 14`，ASR 识别为 `爱疯十四`。 | **热词注入**：在解码阶段给 `iPhone` 和 `14` 加偏置。<br>

<br>**模糊检索**：RAG 检索时使用拼音或 Embedding 相似度，而非精确匹配。 |
| **多音字实体** | 歌手 `那英` (Na Ying)，ASR 可能把 `那` 识别为 `na4`。 | **强制发音典**：在 Lexicon 中强制定义 `那英 n a1 y ing1`。 |
| **术语归一化** | 用户说 `k8s`，知识库里是 `Kubernetes`。 | **同义词表 (Synonyms)**：在 ITN 后挂载一个**领域术语映射层**。 |

---

## 19.7 常见陷阱 (Gotchas) 与调试技巧

1. **“零”的消失与重现**
* TN: `101`  `一百零一` (有零)。
* TN: `110`  `一百一十` (无零，虽然有人读一百一)。
* **Gotcha**: 不同的 TTS 引擎生成的合成数据，对“零”的处理可能不一致，需清洗。


2. **地址中的数字**
* “长安街1号” vs “长安街一号”。
* **建议**: 地址类数字通常 ITN 还原为阿拉伯数字，因为便于导航输入。


3. **负号与连接符**
* `-5` (负五) vs `3-5` (三到五)。
* **正则技巧**: 如果 `-` 前面有空格或行首，且后面跟数字，大概率是“负”。如果两边都是数字，大概率是“到”或“至”。


4. **小数点陷阱**
* 英文 `3.14` 读 `three point one four`。
* 章节 `Chapter 3.14` 读 `three point one four`。
* **IP地址** `192.168.1.1` 读 `one nine two dot one six eight...` (point vs dot)。



---

## 19.8 练习题

### 基础题 (50%)

<details>
<summary><strong>Q1: 混合文本 TN 处理</strong></summary>

**题目**：请写出文本 `我买了2个iPhone 15 Pro。` 的理想训练文本（TN结果）。





**提示**：注意空格、量词前的数字读法、英文的大小写策略。

<details>
<summary><strong>Q2: 时间 ITN 还原</strong></summary>

**题目**：ASR 输出流为 `下 午 三 点 一 刻`，ITN 应输出什么？如果是 `下 午 三 点 十 五` 呢？





**提示**：书面语规范化。

### 挑战题 (50%)

<details>
<summary><strong>Q3: 歧义正则设计</strong></summary>

**题目**：设计一个简单的逻辑（伪代码），区分文本中的 `119` 是读作 `yāo yāo jiǔ` (火警) 还是 `yī bǎi yī shí jiǔ` (数量)。





**提示**：利用上下文关键词（context words）。

<details>
<summary><strong>Q4: 粤语 ITN 策略</strong></summary>

**题目**：在粤语会议纪要场景下，ASR 识别出 `我 唔 同意 佢 嘅 讲法`。客户要求输出“正式商务中文”。请问这属于 ITN 还是翻译？如何实现？





**答案**：
这严格来说属于 **机器翻译 (MT)** 或 **风格重写 (Style Transfer)**，超出了标准 ITN (基于规则) 的范畴。
但在大模型时代，可以将其视为广义 ITN。
**实现**：使用 MLLM 进行后处理，Prompt: "将以下粤语口语转换为标准普通话书面语"。
输出：`我不同意他的说法。`

</details>
